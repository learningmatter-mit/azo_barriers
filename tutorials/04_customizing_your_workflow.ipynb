{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f3cc573",
   "metadata": {},
   "source": [
    "# Customizing your workflow\n",
    "In the previous tutorial we saw how to load the data you create in a simulation. Here we'll go into some more detail about how to customize your simulations. \n",
    "\n",
    "Let's start with imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "186596c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76fd8552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b83a1d4",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The file `examples/run.sh` calls `barriers/utils/workflow.py`, which runs a set of calculations in series (relaxed scan, conformer generation, etc.). The script loads simulation details from the file `job_info.json`. Let's take a look at that file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1b64685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weightpath': '../models/singlet/0',\n",
       " 'triplet_weightpath': '../models/triplet/0',\n",
       " 'smiles_list': ['CCN(CC)c1ccc(/N=N\\\\c2ccc(NC(=O)C[N+](CC)(CC)CC)cc2)cc1',\n",
       "  'CCN(c1ccccc1)c1cc(C(=O)NOC)ccc1/N=N/c1ccc(C(=O)NOC)cc1N(CC)c1ccccc1'],\n",
       " 'device': 2,\n",
       " 'rdkit_confgen': {},\n",
       " 'relaxed_scan': {},\n",
       " 'confgen': {'num_parallel': 10, 'num_in_chunk': 100},\n",
       " 'evf': {'num_parallel': 1},\n",
       " 'hessian': {'num_parallel': 2},\n",
       " 'irc': {'num_parallel': 1},\n",
       " 'triplet_crossing': {'num_parallel': 1}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = \"../examples/job_info.json\"\n",
    "with open(path, 'r') as f:\n",
    "    info = json.load(f)\n",
    "    \n",
    "display(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00d7400",
   "metadata": {},
   "source": [
    "Here's what each key means:\n",
    "\n",
    "- `weightpath`: The directory in which the singlet model is saved. The model should be saved with the name `best_model` in the directory `weightpath`\n",
    "- `triplet_weightpath`: Same as `weightpath`, but for the triplet model\n",
    "- `smiles_list`: List of SMILES strings for the molecules you want to analyze\n",
    "- `device`: Where to run calculations. Either an integer for the GPU you want to use or `cpu` if you don't have a GPU.\n",
    "- `rdkit_confgen`: Any custom details for the RDKit conformer generation stage\n",
    "- `relaxed_scan`: Any custom details for the relaxed scan generation stage\n",
    "- `confgen`: Any custom details for the conformer generation stage\n",
    "- `evf`: Any custom details for the eigenvector following generation stage\n",
    "- `hessian`: Any custom details for the Hesssian calculation on the cis and strans geometries\n",
    "- `irc`: Any custom details for the intrinsic reaction coordinate stage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9899a591",
   "metadata": {},
   "source": [
    "### Parallelization\n",
    "\n",
    "In this example, we've set `num_parallel` for many of the stages. This tells you how many jobs you want to run in parallel at a time (e.g. for 2 molecules and 4 mechanisms, you'll have 8 TSs and 4 endpoints, for a total of 12 conformer generation jobs, so you may want to run all of those in parallel). \n",
    "\n",
    "#### Details of parallelization\n",
    "The simplest way to parallelize jobs is to run $N$ separate job scripts, one for each job, and have them all use the same GPU. However, we found that the more jobs you run this way, the slower each job becomes. In fact, past $N\\approx 3$, the ratio $(\\text{number of jobs}) \\ / \\ (\\text{total time})$ stops increasing.\n",
    "\n",
    "This can be fixed by running one script only, then putting the geometries from all the calculations into one batch, and evaluating the model on that batch. We implemented this batching approach for conformer generation since it was by far the slowest stage in our workflow. For that reason, you can get very good speedups up until `num_parallel` $\\approx 50$ in conformer generation. Since the other methods use separate job scripts for parallelization, we recommend setting `num_parallel`$=4$ for those jobs.\n",
    "\n",
    "Lastly, note that conformer generation has a second parallelization key, called `num_in_chunk`. Batched conformer generation runs metadynamics and optimizations for each species until its lowest-energy conformer stops decreasing in energy. It then replaces this species with another species that's waiting in the queue. Once all species are done, it performs a final tight optimization on each. `num_in_chunk` is the number of species in the queue. For example, if you had 300 species and `num_in_chunk`$=100$, you'd completely finish the first 100 species before moving starting the next 200."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca43857",
   "metadata": {},
   "source": [
    "## Specific job details\n",
    "\n",
    "The script we're running calls sub-scripts, one for each stage of the workflow, which are located in `scripts`. We can see that here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff438e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['irc',\n",
       " 'relaxed_scan',\n",
       " 'confgen',\n",
       " 'hessian',\n",
       " 'triplet_crossing',\n",
       " 'full_workflow',\n",
       " 'rdkit_confgen',\n",
       " 'evf']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['batch.sh', 'job.sh', 'test', 'default_details.json']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(os.listdir('../scripts'))\n",
    "display(os.listdir('../scripts/relaxed_scan'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1109517d",
   "metadata": {},
   "source": [
    "We can see that `scripts` has a sub-folder for each component of the workflow. Each sub-folder has job scripts (`job.sh` for a single job and `batch.sh` for a batched job), a `test` folder for testing the code, and `default_details.json`. This last file has the default details for the job. By looking at those details, we can see what parameters can be customized. You can customize any parameter by setting its value in `job_info.json` as described above.\n",
    "\n",
    "Now we'll look at those details for each stage of the workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229c9a52",
   "metadata": {},
   "source": [
    "### `rdkit_confgen`\n",
    "\n",
    "This stage generates initial conformer guesses using a [script in the Neural Force Field repository](https://github.com/learningmatter-mit/NeuralForceField/blob/master/nff/utils/confgen.py) that calls [RDKit](https://www.rdkit.org/docs/GettingStartedInPython.html). Let's look at the default details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e8b6e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'csv_data_path': 'smiles.csv',\n",
       " 'max_confs': 200,\n",
       " 'forcefield': 'mmff',\n",
       " 'nconf_gen': 2000,\n",
       " 'e_window': 5.0,\n",
       " 'rms_tol': 0.1,\n",
       " 'prun_tol': 0.01,\n",
       " 'job_dir': 'confs',\n",
       " 'log_file': 'confgen.log',\n",
       " 'rep_e_window': 5.0,\n",
       " 'fallback_to_align': False,\n",
       " 'temp': 298.15,\n",
       " 'pickle_save_dir': '.',\n",
       " 'summary_save_dir': '.',\n",
       " 'clean_up': True}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_template = '../scripts/{name}/default_details.json'\n",
    "path = path_template.format(name='rdkit_confgen')\n",
    "\n",
    "with open(path, 'r') as f:\n",
    "    details = json.load(f)\n",
    "    \n",
    "display(details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3498df2",
   "metadata": {},
   "source": [
    "Here's what each key means:\n",
    "\n",
    "- `csv_data_path`: If you're running this script by itself, it'll look for a CSV path with a list of SMILES strings. Our workflow script generates this file automatically.\n",
    "- `max_confs`: Maximum number of conformers to keep at the very end\n",
    "- `forcefield`: Classical force field to use for optimization\n",
    "- `nconf_gen`: How many initial conformers to generate (duplicates and high-energy conformers will get discarded)\n",
    "- `e_window`: Only keep conformers with relative energy below `e_window`, in kcal/mol\n",
    "- `rms_tol`: Conformers with RMSD below `rms_tol` Angstroms are considered duplicates and discarded after optimization.\n",
    "- `prun_tol`: Same idea as `rms_tol`, but for the initial conformer generation by RDKit.\n",
    "- `job_dir`: Where to save the `xyz` files and scratch work from conformer generation\n",
    "- `log_file`: Where to log notes and errors\n",
    "- `rep_e_window`: Only log information about conformers with energies under `rep_e_window` kcal/mol\n",
    "- `fallback_to_align`: Use `obabel --align` if `obfit` fails\n",
    "- `temp`: Temperature in Kelvin for computing statistical weights of each conformer\n",
    "- `pickle_save_dir`: Directory in which to save the pickle file with information about each conformer\n",
    "- `summary_save_dir`: Directory in which to save the json file with a summary of the results, without the actual conformers themselves\n",
    "- `clean_up`: Remove scratch information once the job is done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9a205e",
   "metadata": {},
   "source": [
    "### `relaxed_scan`\n",
    "This stage performs a relaxed scan from an initial conformer guess to a TS guess. Let's look at the default details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3d36b49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nxyz': None,\n",
       " 'smiles': None,\n",
       " 'weightpath': None,\n",
       " 'num_parallel': 4,\n",
       " 'nnid': '',\n",
       " 'en_key': 'energy_0',\n",
       " 'model_kwargs': None,\n",
       " 'device': 0,\n",
       " 'cutoff': 5.0,\n",
       " 'cutoff_skin': 2.0,\n",
       " 'nbr_list_update_freq': 10,\n",
       " 'directed': True,\n",
       " 'requires_large_offsets': False,\n",
       " 'opt_config': 'neuraloptimizer',\n",
       " 'opt_max_step': 500,\n",
       " 'fmax': 0.05,\n",
       " 'fmax_tight': 0.05,\n",
       " 'num_steps': 20,\n",
       " 'opt_type': 'BFGS',\n",
       " 'use_rdkit': False,\n",
       " 'end_constraints': {'hookean': {'atoms': {'idx': None,\n",
       "    'template_smiles': 'c1ccc(/N=N/c2ccccc2)cc1',\n",
       "    'targets': None,\n",
       "    'force_consts': 2242.34},\n",
       "   'bonds': {'idx': None,\n",
       "    'template_smiles': 'c1ccc(/N=N/c2ccccc2)cc1',\n",
       "    'targets': None,\n",
       "    'force_consts': 2242.34},\n",
       "   'angles': {'idx': None,\n",
       "    'template_smiles': 'c1ccc(/N=N/c2ccccc2)cc1',\n",
       "    'targets': None,\n",
       "    'force_consts': 627.5},\n",
       "   'dihedrals': {'idx': None,\n",
       "    'template_smiles': 'c1ccc(/N=N/c2ccccc2)cc1',\n",
       "    'targets': None,\n",
       "    'force_consts': 627.5}}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(path_template.format(name='relaxed_scan'), 'r') as f:\n",
    "    details = json.load(f)\n",
    "    \n",
    "display(details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d590cc70",
   "metadata": {},
   "source": [
    "Here's what each key means:\n",
    "\n",
    "- `nxyz`: Coordinates of the starting geometry. Provided automatically in the workflow script from the previous RDKit stage\n",
    "- `smiles`: SMILES string of the species. Provided automatically in the workflow script\n",
    "- `weightpath`: Directory to model\n",
    "- `num_parallel`: Number of jobs to run in parallel\n",
    "- `nnid`: Can join the strings `weightpath` and `nnid` to give the model directory if you want\n",
    "- `en_key`: Name of the energy key outputted by the model\n",
    "- `model_kwargs`: Any keyword arguments you want to provide to the model when calling it\n",
    "- `device`: Device to run the calculation on\n",
    "- `cutoff`: Neighbor list cutoff for the model\n",
    "- `cutoff_skin`: Use `cutoff` $+$ `cutoff_skin` as the cutoff when generating neighbors, and then only take neighbors within `cutoff` of each other. This is done because we only recompute the neighbors every few steps, so we don't want to miss any if an atom comes into another atoms' neighborhood between updates.\n",
    "- `nbr_list_update_freq`: Number of steps between neighbor list updates in the optimization\n",
    "- `directed`: Use a directed neighbor list (must be the case for PaiNN)\n",
    "- `requires_large_offsets`: Use large offsets for periodic structures (not relevant for us)\n",
    "- `opt_config`: Name of the script to use for the optimization at each stage of the scan\n",
    "- `opt_max_step`: Maximum number of optimization steps\n",
    "- `fmax`: Maximum force threshold for convergence optimization ($\\mathrm{eV} \\ / \\ A$).\n",
    "- `fmax_tight`: Same as `fmax`, but for a more tight optimization on the last geometry after the scan is complete. Make sure to use the same value as for `fmax_tight` in conformer generation (see below).\n",
    "- `num_steps`: Number of steps to use in the relaxed scan\n",
    "- `opt_type`: Name of the ASE optimization engine to use\n",
    "- `use_rdkit`: Use RDKit instead of ASE to adjust the atom positions to their target values at each step\n",
    "- `end_constraints`: Constraints to apply to the geometry at the last stage of the scan. The values at intermediate steps are interpolated between the starting values and the final values.\n",
    "    - The constraint dictionary has keys for each type of constraint (see [here](https://wiki.fysik.dtu.dk/ase/ase/constraints.html) for a list of built-in ASE constraints). We use `hookean`, which provides a spring force to keep things at their target values.\n",
    "    - Within `hookean`, we can specify constraints to keep atoms at certain positions (`atoms`), to keep bonds at certain lengths (`bonds`) or to keep angles/dihedral angles at certain values (`angles`/`dihedrals`)\n",
    "    - Whichever coordinate you constrain, you have to supply `idx`, a list of indices for the coordinates of interest. For example:\n",
    "         - `\"atoms\": [0, 6, 9]`; `\"bonds\": [[3, 4], [5, 6], [7, 8]]`; `\"angles\": [[3, 4, 9], [6, 7, 9]]`; `\"dihedrals\": [[3, 4, 9, 10], [0, 3, 4, 5], [1, 2, 3, 4]]`\n",
    "    - You can also ask to use the indices from a reference molecule, given by `template_smiles`. The program then does a substructure search to figure out what those indices are in the current molecule. \n",
    "        - This is what we do in the workflow: we set `template_smiles` to `'c1ccc(/N=N/c2ccccc2)cc1'` (azobenzene), and then supply the indices as `[3, 4, 5, 6]` for the dihedrals (these are the CNNC atoms in azobenzene), and/or  `[3, 4, 5]` and `[4, 5, 6]` for the angles\n",
    "    - Lastly, you must supply force constants in units of kcal or kcal/A.\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7a570e",
   "metadata": {},
   "source": [
    "### `confgen`\n",
    "This stage performs conformer generation on the TS guesses from the relaxed scans, and also on the RDKit guesses for the *cis* and *trans* geometries. Let's look at the default details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bdff737",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weightpath': None,\n",
       " 'smiles': None,\n",
       " 'nxyz': None,\n",
       " 'num_parallel': 10,\n",
       " 'num_in_chunk': 100,\n",
       " 'nnid': '',\n",
       " 'en_key': 'energy_0',\n",
       " 'model_kwargs': None,\n",
       " 'device': 0,\n",
       " 'cutoff': 5.0,\n",
       " 'cutoff_skin': 2.0,\n",
       " 'nbr_list_update_freq': 10,\n",
       " 'directed': True,\n",
       " 'requires_large_offsets': False,\n",
       " 'md_type': 'NoseHooverMetaDynamics',\n",
       " 'geom_add_time': 1000,\n",
       " 'mtd_time': None,\n",
       " 'infer_time_from_flex': True,\n",
       " 'time_step': 2.0,\n",
       " 'temperature': 298.15,\n",
       " 'ttime': 50,\n",
       " 'maxwell_temp': None,\n",
       " 'loginterval': 10,\n",
       " 'fixed_atoms': {'idx': [3, 4, 5, 6],\n",
       "  'template_smiles': 'c1ccc(/N=N/c2ccccc2)cc1'},\n",
       " 'constraints': {'hookean': {'bonds': {'idx': None,\n",
       "    'template_smiles': None,\n",
       "    'targets': None,\n",
       "    'force_consts': 2242.34},\n",
       "   'angles': {'idx': None,\n",
       "    'template_smiles': None,\n",
       "    'targets': None,\n",
       "    'force_consts': 627.5},\n",
       "   'dihedrals': {'idx': None,\n",
       "    'template_smiles': None,\n",
       "    'targets': None,\n",
       "    'force_consts': 627.5}}},\n",
       " 'opt_constraints': None,\n",
       " 'enhanced_sampling': {'method': 'NoseHooverMetaDynamics',\n",
       "  'params': {'pushing_params': {'kappa': 0.03,\n",
       "    'k_i': 1.5,\n",
       "    'alpha_i': 0.5,\n",
       "    'bias_type': 'rmsd',\n",
       "    'max_ref_structures': 100000}},\n",
       "  'shake': False},\n",
       " 'exclude_from_rmsd': {'idx': [3, 4, 5, 6],\n",
       "  'template_smiles': 'c1ccc(/N=N/c2ccccc2)cc1'},\n",
       " 'sample_rate_fs': 100,\n",
       " 'lower_e_tol': 0.2,\n",
       " 'max_md_runs': 5,\n",
       " 'min_md_runs': 2,\n",
       " 'fmax_coarse': 0.2,\n",
       " 'fmax_tight': 0.05,\n",
       " 'fmax_vtight': 0.005,\n",
       " 'window_coarse': 15.0,\n",
       " 'window_tight': 8.0,\n",
       " 'window_vtight': 2.5,\n",
       " 'opt_type': 'LBFGS',\n",
       " 'opt_max_step': 1500,\n",
       " 'check_hess': False,\n",
       " 'max_restart_opt': 1,\n",
       " 'crest_dedupe': {'on': True,\n",
       "  'params': {'ethr': 0.15, 'rthr': 0.175, 'bthr': 0.03, 'ewin': 10000}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(path_template.format(name='confgen'), 'r') as f:\n",
    "    details = json.load(f)\n",
    "    \n",
    "display(details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57269151",
   "metadata": {},
   "source": [
    "Here's what each key means (other than the ones we already defined above):\n",
    "- `md_type`: What kind of molecular dynamics (MD) to run to sample geometries\n",
    "- `geom_add_time`: How many fs between adding new geometries to the biasing potential\n",
    "- `mtd_time`: Total metadynamics time, in ps. Given as `None` because we use `infer_from_flex`\n",
    "- `infer_time_from_flex`: Use a molecule flexibility measure to determine the metadynamics time\n",
    "- `time_step`: Time step, in fs\n",
    "- `temperature`: Temperature in Kelvin\n",
    "- `ttime`: $\\tau= \\mathrm{ttime} \\cdot \\mathrm{time\\_step}$ is the Nose-Hoover relaxation time\n",
    "- `maxwell_temp`: Temperature with which to generate initial velocities from Maxwell-Boltzmann distribution. Defaults to $2\\cdot$`temperature` if not specified\n",
    "- `loginterval`: Log MD statistics every `loginterval` steps\n",
    "- `fixed_atoms`: Dictionary telling you which atoms to **fix** (not constrain) during dynamics and optimization. For TS conformer searches, we constrain the CNNC atoms, by setting `idx` to `[3, 4, 5, 6]` and using azobenzene as a template. For cis/trans searches we don't fix these atoms, but we do exclude them from the metadynamics bias (see below)\n",
    "\n",
    "- `constraints`: Any constraints you want to use. Same format as in `relaxed_scan` \n",
    "- `opt_constraints`: Any constraints you want to apply during the optimization portion but not during dynamics\n",
    "- `enhanced_sampling`: Dictionary with information about the enhanced sampling method\n",
    "    - `method`: The method name\n",
    "    - `params`: Any parameters that need to be given for the enhanced sampling method. For metadynamics we specify the number of turn on steps $\\kappa$, the pushing strength $k_i' = k_i / N$, where $N$ is the number of atoms and $k_i'$ is in mHa, the Gaussian width $\\alpha_i$ (in units of $\\mathrm{Bohr}^{-2}$), the bias type (RMSD by default), and the maximum number of reference structures to use in the pushing potential\n",
    "    - `shake`: Whether to use SHAKE to constrain bond lengths\n",
    "\n",
    "- `exclude_from_rmsd`: Any atoms to exclude from the RMSD computation for the pushing potential in metadynamics. We set these to `[3, 4, 5, 6]` with azobenzene as the template SMILES. For TS searches this is redundant, since fixing `[3, 4, 5, 6]` will automatically exclude them from the RMSD. But it is necessary for *cis* and *trans* optimizations, so that we don't accidentally turn *cis* into *trans* and vice-versa.\n",
    "\n",
    "- `sample_rate_fs`: Sample geometries every `sample_rate_fs` fs from dynamics to optimize as conformers\n",
    "- `lower_e_tol`: Tolerance for energy changes, in kcal/mol. If the energy drops by less than `lower_e_tol` after a round of metadynamics + optimization, then no more rounds are performed for that species\n",
    "\n",
    "- `max_md_runs`: maximum number of metadynamics runs\n",
    "- `min_md_runs`: minimum number of metadynamics runs\n",
    "\n",
    "- `fmax_coarse`: Force tolerance during coarse optimization, in $\\mathrm{eV} \\ / \\ A$\n",
    "- `fmax_tight`: Force tolerance during tight optimization, in $\\mathrm{eV} \\ / \\ A$\n",
    "- `fmax_vtight`: Force tolerance during very tight optimization, in $\\mathrm{eV} \\ / A$\n",
    "    - In the paper we used 0.01 for TSs and 0.005 for *cis*/*trans*, and then used 0.005 for EVF. Here for simplicity we've used 0.005 for all, so that we can use the same parameters for all conformer jobs.\n",
    "- `window_coarse`: Only keep conformers with energy below this value during coarse optimization. Given in $\\mathrm{kcal} \\ /  \\ \\mathrm{mol}$\n",
    "- `window_tight`: Only keep conformers with energy below this value during tight optimization. Given in $\\mathrm{kcal} \\ /  \\ \\mathrm{mol}$\n",
    "- `window_vtight`: Only keep conformers with energy below this value during very tight optimization. Given in $\\mathrm{kcal} \\ /  \\ \\mathrm{mol}$\n",
    "\n",
    "\n",
    "- `opt_type`: Name of the optimization engine. We implemented our own custom batched optimizers for BFGS and LBFGS. LBFGS is significantly faster because it does not diagonalize Hessian-related matrices. BFGS becomes very slow when diagonalizing such matrices for all geometries in the batch.\n",
    "\n",
    "- `opt_max_step`: Maximum number of steps in the optimization\n",
    "- `check_hess`: Check Hessian for imaginary frequencies to see if an optimized structure is really a minimum\n",
    "- `max_restart_opt`: Maximum number of optimization restarts if the initial optimization didn't give a true minimum \n",
    "- `crest_dedupe`: Dictionary with information about removing duplicate conformers using `cregen` in the CREST program\n",
    "    - `on`: Whether or not to use this functionality\n",
    "    - `params`: Any parameters for `cregen`. See the [cregen documentation](https://xtb-docs.readthedocs.io/en/latest/crestcmd.html#ensemble-sorting) for more details on these parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9060580c",
   "metadata": {},
   "source": [
    "### `evf`\n",
    "This stage performs eigenvector following on the TS conformers from `confgen`. Let's look at the default details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f7948dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weightpath': None,\n",
       " 'nxyz': None,\n",
       " 'num_parallel': 4,\n",
       " 'nnid': '',\n",
       " 'device': 0,\n",
       " 'ev_kwargs': {'maxstepsize': 0.15,\n",
       "  'maxstep': 1000,\n",
       "  'convergence': 0.005,\n",
       "  'method': 'Powell'},\n",
       " 'atoms_kwargs': {'cutoff': 5.0,\n",
       "  'cutoff_skin': 2.0,\n",
       "  'nbr_update_period': 1,\n",
       "  'directed': True,\n",
       "  'requires_large_offsets': False},\n",
       " 'calc_kwargs': {'en_key': 'energy_0',\n",
       "  'properties': ['energy', 'forces'],\n",
       "  'model_kwargs': None},\n",
       " 'thermo_kwargs': {'flip_all_but_ts': True, 'imag_cutoff': -10},\n",
       " 'cutoff_to_be_ts': -200,\n",
       " 'confs_per_ts': 5}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(path_template.format(name='evf'), 'r') as f:\n",
    "    details = json.load(f)\n",
    "    \n",
    "display(details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4461746f",
   "metadata": {},
   "source": [
    "Here's what each key means (other than the ones we already defined above):\n",
    "- `ev_kwargs`: A dictionary with parameters for the eigenvector following routine:\n",
    "    - `maxstepsize`: Maximum step size, in Angstroms\n",
    "    - `convergence`: Same as `fmax`, in $\\mathrm{eV} \\ / A $\n",
    "    - `method`: Method for updating the Hessian. The default is the Powell method \n",
    "- `atoms_kwargs`: A dictionary with parameters for the `AtomsBatch` objects (basically our Neural Force Field version of ASE atoms objects). All keys in this dictionary were defined above; in other methods they existed inside the main dictionary.\n",
    "- `calc_kwargs`: A dictionary with parameters for the ASE calculator using the model. Most keys in this dictionary were defined above; in other methods they existed inside the main dictionary. The only new key is `properties`, which tells you what you want to calculate (energies, forces, or both)\n",
    "- `thermo_kwargs`: Information about quantities in thermodynamic calculations:\n",
    "    - `flip_all_but_ts`: Turn all but the lowest imaginary frequency into a positive frequency\n",
    "    - `imag_cutoff`: Any imaginary frequency with magnitude under `imag_cutoff` $\\mathrm{cm}^{-1}$ can be flipped and considered real\n",
    "- `cutoff_to_be_ts`: If the lowset imaginary frequency has magnitude under `cutoff_to_be_ts` $\\mathrm{cm}^{-1}$, then it is not considered to be a true TS\n",
    "- `confs_per_ts`: How many TS conformers to optimize with eigenvector following"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e4c510",
   "metadata": {},
   "source": [
    "### `hessian`\n",
    "This stage performs Hessian calculations on the confgen-optimized *cis* and *trans* conformers. Let's look at the default details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7392c514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weightpath': None,\n",
       " 'nxyz': None,\n",
       " 'num_parallel': 4,\n",
       " 'nnid': '',\n",
       " 'atoms_kwargs': {'cutoff': 5.0,\n",
       "  'cutoff_skin': 2.0,\n",
       "  'nbr_update_period': 1,\n",
       "  'directed': True,\n",
       "  'requires_large_offsets': False},\n",
       " 'calc_kwargs': {'en_key': 'energy_0',\n",
       "  'properties': ['energy', 'forces'],\n",
       "  'model_kwargs': None},\n",
       " 'device': 0,\n",
       " 'analytical_hessian': False,\n",
       " 'temperature': 298.15,\n",
       " 'pressure': 101325,\n",
       " 'imag_cutoff': -10,\n",
       " 'rotor_cutoff': 50,\n",
       " 'confs_per_endpoint': 1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(path_template.format(name='hessian'), 'r') as f:\n",
    "    details = json.load(f)\n",
    "    \n",
    "display(details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264b339e",
   "metadata": {},
   "source": [
    "Here's what each key means (other than the ones we already defined above):\n",
    "\n",
    "- `analytical_hessian`: Calculate the Hessian analytically. This is turned off by default because it takes up a lot of memory for bigger molecules. To avoid unexpected out-of-memory errors, we compute the Hessian numerically with ASE\n",
    "- `pressure`: Pressure for the thermo calculation, in Pa\n",
    "- `rotor_cutoff`: Cutoff in $\\mathrm{cm}^{-1}$ used in the interpolation between harmonic oscillator and rigid rotor treatments of low-frequency modes\n",
    "- `confs_per_endpoint`: How many conformers to perform Hessian calculations on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03fd2b4",
   "metadata": {},
   "source": [
    "### `irc`\n",
    "This stage performs intrinsic reaction coordinate (IRC) calculations on optimized TSs. Let's look at the default details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0900ad86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nxyz': None,\n",
       " 'weightpath': None,\n",
       " 'num_parallel': 4,\n",
       " 'nnid': '',\n",
       " 'device': 0,\n",
       " 'en_key': 'energy_0',\n",
       " 'model_kwargs': None,\n",
       " 'init_displ_de': 0.000398,\n",
       " 'max_iter': 5000,\n",
       " 'tol_max_g': 0.002,\n",
       " 'tol_rms_g': 0.0005,\n",
       " 'scale_displ_sd_corr': 0.3333,\n",
       " 'sd_corr_parabolic_fit': True,\n",
       " 'do_sd_corr': True,\n",
       " 'interpolate_only': True,\n",
       " 'sd_parabolic_fit': True,\n",
       " 'adapt_scale_disp': True,\n",
       " 'scale_displ_sd': 0.15,\n",
       " 'cutoff': 5.0,\n",
       " 'cutoff_skin': 2.0,\n",
       " 'nbr_update_period': 1,\n",
       " 'directed': True,\n",
       " 'requires_large_offsets': False,\n",
       " 'confs_per_ts': 1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(path_template.format(name='irc'), 'r') as f:\n",
    "    details = json.load(f)\n",
    "    \n",
    "display(details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda60bcc",
   "metadata": {},
   "source": [
    "Here's what each key means (other than the ones we already defined above):\n",
    "\n",
    "- `init_displ_de`: Target energy change after the first step in the direction of the imaginary mode. Given in Ha\n",
    "- `max_iter`: Maximum number of steps to generate the path\n",
    "- `tol_max_g`: Maximum gradient tolerance for convergence (same as `fmax`), given in $\\mathrm{Ha} \\ / \\ \\mathrm{Bohr}$\n",
    "- `rms_max_g`: RMS gradient tolerance for convergence (same as `fmax`), given in $\\mathrm{Ha} \\ / \\ \\mathrm{Bohr}$\n",
    "- `scale_displ_sd_corr`: Factor for scaling the correction to the steepest descent (SD) step\n",
    "- `sd_corr_parabolic_fit`: Do a parabolic fit for finding the optimal SD step length \n",
    "- `do_sd_corr`: Apply a correction to the first SD step\n",
    "- `interpolate_only`: Only allow interpolation for parabolic fit, not extrapolation\n",
    "- `sd_parabolic_fit`: Do a parabolic fit for finding the optimal SD step length\n",
    "- `adapt_scale_disp`: Modify `scale_displ_sd` when the step size becomes smaller or larger\n",
    "- `scale_displ_sd`: Factor for scaling the first SD step\n",
    "- `confs_per_ts`: How many EVF-optimized TS conformers to perform IRC on\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db827db",
   "metadata": {},
   "source": [
    "### `triplet_crossing`\n",
    "This stage performs a search for the lowest energy singlet-triplet crossing on either side of the rotational TS. The initial guesses are generated by generating a forward- and backward-IRC path, and looking for crossings along each. Let's look at the default details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c44bf12c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nxyz': None,\n",
       " 'nnid': '',\n",
       " 'weightpath': None,\n",
       " 'num_parallel': 4,\n",
       " 'triplet_params': {'nnid': '',\n",
       "  'weightpath': None,\n",
       "  'en_key': 'energy_0',\n",
       "  'model_kwargs': None,\n",
       "  'cutoff': 5.0},\n",
       " 'triplet_nnid': '',\n",
       " 'init_displ_de': 0.000398,\n",
       " 'max_iter': 500,\n",
       " 'tol_max_g': 0.0001,\n",
       " 'tol_rms_g': 1e-05,\n",
       " 'scale_displ_sd_corr': 0.3333,\n",
       " 'sd_corr_parabolic_fit': True,\n",
       " 'do_sd_corr': True,\n",
       " 'interpolate_only': True,\n",
       " 'sd_parabolic_fit': True,\n",
       " 'adapt_scale_disp': True,\n",
       " 'scale_displ_sd': 0.01,\n",
       " 'alpha_kcal': 12.55,\n",
       " 'opt_type': 'BFGS',\n",
       " 'fmax': 0.005,\n",
       " 'opt_max_step': 1500,\n",
       " 'nbr_list_update_freq': 10,\n",
       " 'en_key': 'energy_0',\n",
       " 'model_kwargs': None,\n",
       " 'cutoff': 5.0,\n",
       " 'device': 0,\n",
       " 'cutoff_skin': 2.0,\n",
       " 'directed': True,\n",
       " 'requires_large_offsets': False,\n",
       " 'compute_hessian': False,\n",
       " 'temperature': 298.15,\n",
       " 'pressure': 101325,\n",
       " 'imag_cutoff': -10,\n",
       " 'rotor_cutoff': 50,\n",
       " 'k_isc_params': {'h_so_inv_cm': 20, 'method': 'wkb_analytical'}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(path_template.format(name='triplet_crossing'), 'r') as f:\n",
    "    details = json.load(f)\n",
    "    \n",
    "display(details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f91c6d",
   "metadata": {},
   "source": [
    "Here's what each key means (other than the ones we already defined above):\n",
    "\n",
    "- `triplet_params`: Parameters related to calculations of the triplet enegries and forces. By default no `weightpath` is given, but if `triplet_weightpath` is specified in the workflow JSON, then it'll automatically get put into `triplet_params-\n",
    "- `triplet_nnid`: `nnid` for the triplet model\n",
    "- `alpha_kcal`: $\\alpha$ parameter for the singlet-triplet optimization (see SI of the paper). Given in kcal/mol\n",
    "- `compute_hessian`: Compute singlet and triplet Hessians at the crossing points, and get the associated thermostatistical quantities. By default we don't do this and just use the quantities from the TS that generated the crossing points\n",
    "- `k_isc_params`: Parameters for computing the intersystem crossing rate:\n",
    "    - `h_so_inv_cm`: The spin-orbit coupling strength $H_{\\mathrm{SO}}$, given in $\\mathrm{cm^{-1}}$. By default we take this to be $20 \\ \\mathrm{cm^{-1}}$ for all derivatives\n",
    "    - `method`: The method used to calculate the rate. By default we use `wkb_analytical`, which computes the rate using the analytical method based on the WKB approximation, from [this paper](https://pubs.acs.org/doi/full/10.1021/jp503794j?casa_token=E7gsTA6AG9sAAAAA%3AcYFKUI4PZn1E1rC7f5ULN4p1hMXFPhj_TUb8iYm3XNp8Ut9w-Tf0wP_Uv4dxe9Qz4XCi2eHkll8P_Nj1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088f0b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:barriers]",
   "language": "python",
   "name": "barriers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
